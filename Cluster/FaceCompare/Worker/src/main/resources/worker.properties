# kafka地址与端口号 e: e.x:172.18.18.100:9092,172.18.18.101:9092,172.18.18.102:9092
kafka.bootstrap.servers=172.18.18.100:9092,172.18.18.101:9092,172.18.18.102:9092
kafka.maximum.time=1000
kafka.topic=face

es.cluster.name=hbase2es-cluster
es.hosts=172.18.18.103
es.cluster.port=9300

#cluster.dir=/opt/hzgc/bigdata
#facecompare.dir=/opt/hzgc/compare

#zookeeper连接地址与端口 e: e.x:172.18.18.100:2181,172.18.18.101:2181,172.18.18.102:2181
zookeeper.address=172.18.18.100:2181,172.18.18.101:2181,172.18.18.102:2181

cluster.name=hzgc
#worker参数配置
worker.buffer.size.max=1000
#内存中缓存数据的最大值
worker.cach.size.max=40000000
#内存数据的检查时间间隔
worker.memory.check.time=1800000
#内存中记录的过期时间
work.record.time.out=180
#检查任务列表的时间间隔
work.check_task.time=1000
#文件检查时间间隔
worker.file.check.time=1800000
#文件保存路径
worker.file.path=matedata
#文件保存大小
worker.file.size=134217728
#文件流过期时间
worker.stream.time.out=2
#数据持久化的文件系统 0 本地  1 HDFS
worker.file.save.system=0
#每个线程计算多少天的数据
days.per.thread=4
#不使用多线程的最大天数
days.without.multithread=8
#第一次对比结果取多少
first.compare.result.count=500
worker.address=localhost
tasktracker.group=facecompare-tracker
worker.readfiles_per_thread=1
worker.executors.to.compare=10
worker.executors.to.loadfile=15
#持久化触发方式 0 定期触发  1定量触发
worker.flush.program=0

#是否删除过期文件
delete.open=1
